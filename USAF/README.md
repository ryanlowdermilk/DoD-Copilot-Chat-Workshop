# USAF Copilot Chat Hands-On Lab: Proctor Guide
## 6 Copilot Capabilities Across Real-World Air Force Scenarios

**Version:** October 08, 2025  
**Classification:** UNCLASSIFIED  
**Duration:** 3 hours (6 scenarios √ó 20-25 min each)

---

## Table of Contents

- [Lab Overview](#lab-overview)
- [Prerequisites & Setup](#prerequisites--setup)
- [Scenario Modules](#scenario-modules)
  - [Scenario 1: Language Understanding & Generation](#scenario-1-language-understanding--generation)
  - [Scenario 2: Reasoning & Decision Support](#scenario-2-reasoning--decision-support)
  - [Scenario 3: Data Analysis & Visualization](#scenario-3-data-analysis--visualization)
  - [Scenario 4: Automation & Orchestration](#scenario-4-automation--orchestration)
  - [Scenario 5: Search & Retrieval](#scenario-5-search--retrieval)
  - [Scenario 6: Personalization & Context Awareness](#scenario-6-personalization--context-awareness)
- [Quick Reference](#quick-reference)

---

## Lab Overview

This guide provides proctors with a structured framework to facilitate a 3-hour hands-on lab for US Air Force personnel on leveraging standalone Copilot Chat. The lab focuses on six independent real-world scenarios, each highlighting a unique Copilot capability integrated with Microsoft 365 applications in a DoD environment.

### Training Objectives
- Demonstrate how standalone Copilot Chat enhances productivity in USAF operational tasks without relying on integrated M365 Copilot features or web grounding.
- Teach progressive prompt building to optimize Copilot outputs for USAF-specific contexts.
- Build skills in copying/pasting between Copilot Chat and M365 apps for secure, compliant workflows.
- Highlight meta-prompting and chain of reasoning techniques for advanced usage.
- Ensure participants understand Copilot's role in A-staff focus areas like manpower, operations, logistics, communications, and intelligence.

### Target Audience Description
- Primary personas: Junior Airmen (E1-E4) and Officers (O1-O2) performing entry-level tasks; NCOs (E5-E7) and mid-level Officers (O3-O4) handling supervisory duties.
- Skill level: L100-L200 (beginner to intermediate familiarity with M365 apps and basic prompting).
- Environment: USAF installations such as Joint Base San Antonio, Nellis AFB, or Wright-Patterson AFB, with emphasis on classified/sensitive operations.

### Lab Structure
The lab consists of six independent scenarios, each lasting 20-25 minutes. Scenarios do not build on each other and can be reordered if needed. Each focuses on one Copilot capability, one USAF focus area, and one M365 application.

### Facilitation Approach
- Guide participants through technical steps without scripted dialogue.
- Encourage hands-on practice with progressive prompts.
- Monitor for compliance with DoD restrictions (no web grounding or integrated Copilot).
- Allocate time for discussion on meta-prompting and chain of reasoning.

### Required Materials/Setup
- Laptops with access to standalone Copilot Chat (browser or app) and M365 apps (Outlook, Word, Excel, Power Automate, Power BI, Teams).
- Sample data files/templates for each scenario (e.g., mock email threads, datasets).
- Projector for demonstrating steps if needed.
- Secure DoD network environment.

### Timing Breakdown
- ‚è±Ô∏è Introduction: 10-15 minutes
- ‚è±Ô∏è Each Scenario: 20-25 minutes (including setup, steps, and discussion)
- ‚è±Ô∏è Breaks: 10 minutes between scenarios 3 and 4
- ‚è±Ô∏è Wrap-up: 10-15 minutes

---

## Prerequisites & Setup

### Pre-Session Preparation Checklist
- Verify all participant devices have standalone Copilot Chat enabled (no M365 Copilot integration).
- Prepare sample datasets: Mock emails for Outlook, spreadsheets for Excel, dashboards for Power BI, etc.
- Test copy/paste workflows between Copilot Chat and M365 apps.
- Ensure no internet access or web grounding is enabled per DoD compliance.
- Distribute any pre-lab reading on basic Copilot usage.

### Technical Environment Verification
- Confirm access to NIPR network for unclassified tasks.
- Check that Copilot Chat operates offline (using local processing only).
- Validate M365 app versions: Latest DoD-approved builds.
- Troubleshoot any SIPR restrictions if scenarios involve sensitive data.

### Required Attendee Access/Accounts
- Active DoD CAC-enabled accounts for M365 and Copilot Chat.
- Permissions for read/write in relevant apps (e.g., Power Automate for workflow design).

### Pre-Work Attendees Should Complete
- Review Microsoft Learn module on standalone Copilot Chat basics.
- Familiarize with M365 apps used in scenarios.
- No advanced pre-work required for L100-L200 level.

### Expected Baseline Knowledge for Attendees
- Basic navigation of M365 apps.
- Understanding of USAF A-staff terminology (e.g., EPR/OPR, mission capability rates).
- Entry-level prompting skills (e.g., simple queries in Copilot Chat).

---

## Scenario Modules

### Scenario 1: Language Understanding & Generation
**Application:** Outlook | **USAF Focus:** A1 (Manpower & Personnel) | **Duration:** 20-25 min

#### Scenario Context
At Joint Base San Antonio, a Senior Airman (E-4) in the Manpower Flight is processing a week's worth of emails on quarterly award packages. The task involves summarizing threads, drafting responses to squadron commanders, and extracting action items for EPR/OPR updates. This scenario demonstrates how Copilot streamlines personnel correspondence in a fast-paced USAF environment.

#### Copilot Capability Focus
- Primary: Language Understanding & Generation
- Sub-capabilities: Summarization, content rewriting for tone, professional drafting
- Application to USAF: Enhances efficiency in handling A1 tasks like award nominations and leave requests, ensuring compliance with AFI 36-2406 for performance reports.

#### Progressive Prompt Building

##### Iteration 1: Basic Prompt
```
Summarize this email thread about quarterly award packages.
```
- What this prompt does: Provides a basic overview of the thread.
- Output example: A short paragraph listing key points.
- Limitations: Lacks USAF-specific context, may miss deadlines or ranks.

##### Iteration 2: Add Context
```
Summarize this email thread about quarterly award packages for the 502nd Air Base Wing, including key personnel involved like squadron commanders and deadlines for EPR submissions.
```
- How context improves output: Incorporates USAF terminology and details for relevance.
- Comparison to iteration 1: More structured, highlights ranks and A1 processes.

##### Iteration 3: Add Specificity
```
Summarize this email thread about quarterly award packages for the 502nd Air Base Wing. Use professional military tone, extract action items with deadlines, and draft a response email to the squadron commander (Lt Col Smith) acknowledging receipt and next steps per AFI 36-2406.
```
- Why specificity matters: Ensures output matches DoD standards for tone and format.
- Improved output quality: Includes drafted email with proper salutations.

##### Iteration 4: Final Optimized Prompt
```
Summarize this email thread about quarterly award packages for the 502nd Air Base Wing. Extract action items and deadlines, rewrite in professional military tone suitable for a Senior Airman communicating with officers. Draft a response email to Lt Col Smith, including greetings, body with key points, and closing per USAF correspondence guidelines.
```
- Final refinements: Adds rank-appropriate language and full structure.
- Complete output example: Summary list + drafted email with "Respectfully," sign-off.

#### Technical Steps
1. Open Outlook and copy a sample email thread into Copilot Chat.
2. Paste Iteration 1 prompt and generate output; copy summary back to Outlook for review.
3. Refine to Iteration 2-4, pasting enhanced prompts and copying generated drafts/responses into new Outlook emails.
4. Verify outputs align with Language Understanding & Generation by checking tone adjustments.

#### Facilitation Notes
> üí° **Tips:**
> - Watch for copy/paste errors between windows.
> - Checkpoint: Ensure prompts include USAF terms like "EPR" for authenticity.
> - Troubleshooting: If output is too casual, add "professional military tone" explicitly.
> - Explain prompt iteration benefits: Shows how adding details reduces revisions.

#### Expected Outcomes
- ‚úÖ Demonstrated summary and drafted email in Outlook.
- ‚úÖ Verified tone adjustment for junior vs. officer communication.
- ‚úÖ Confirmed Language Understanding & Generation via rewritten content.
- ‚úÖ Showed 3-4 prompt iterations leading to optimized output.

#### Discussion Points

**Meta-Prompting**
- How meta-prompting enhances: Guides prompt creation for complex A1 tasks.
- Example: `"Help me create an effective prompt to summarize award package emails. What information should I include, like ranks and deadlines?"`
- When valuable: For beginners building prompts from scratch in personnel actions.

**Chain of Reasoning**
- How to apply: Breaks down summarization logically.
- Example: `"Let's work through this step by step: 1) Identify key senders and ranks. 2) Extract action items and deadlines. 3) Summarize in military tone. 4) Draft response."`
- When improves quality: For detailed correspondence needing accuracy.

**When to Use**
- Use for routine A1 emails to save time.
- Trade-offs: Simple prompts for quick tasks; complex for formal responses.
- Real-world: Processing vMPF updates or decoration submissions.

---

### Scenario 2: Reasoning & Decision Support
**Application:** Word | **USAF Focus:** A3 (Operations) | **Duration:** 20-25 min

#### Scenario Context
At Nellis AFB, a Staff Sergeant (E-5) in the Operations Flight is drafting a squadron training plan. This involves analyzing scheduling conflicts, allocating resources, and mitigating risks for sortie generation. The scenario shows Copilot aiding decision-making in operational planning.

#### Copilot Capability Focus
- Primary: Reasoning & Decision Support
- Sub-capabilities: Recommendation generation, conflict analysis, decision frameworks
- Application to USAF: Supports A3 tasks like operations orders and readiness reports, aligning with AFI 10-401 for deployment planning.

#### Progressive Prompt Building

##### Iteration 1: Basic Prompt
```
Draft a squadron training plan.
```
- What this prompt does: Creates a generic outline.
- Output example: Basic structure without specifics.
- Limitations: Ignores USAF context like flying hours or risks.

##### Iteration 2: Add Context
```
Draft a squadron training plan for the 57th Wing at Nellis AFB, including flying schedules and resource allocation for F-16 pilots.
```
- How context improves output: Adds operational details for relevance.
- Comparison to iteration 1: Includes USAF-specific elements like sortie rates.

##### Iteration 3: Add Specificity
```
Draft a squadron training plan for the 57th Wing at Nellis AFB. Analyze potential scheduling conflicts for F-16 sorties, provide recommendations for resource allocation, and include a decision framework for risk mitigation per AFI 10-401.
```
- Why specificity matters: Ensures analytical depth and compliance.
- Improved output quality: Adds comparative analysis sections.

##### Iteration 4: Final Optimized Prompt
```
Draft a squadron training plan for the 57th Wing at Nellis AFB. Step by step: Analyze scheduling conflicts for F-16 sorties, recommend resource adjustments, create a decision matrix for priorities, and mitigate risks like weather impacts, all in structured Word format.
```
- Final refinements: Incorporates step-by-step for better reasoning.
- Complete output example: Full document with tables for decisions.

#### Technical Steps
1. Open Word and outline a basic plan; copy details into Copilot Chat.
2. Use Iteration 1 prompt to generate draft; paste back into Word.
3. Iterate to 2-4, copying refined outputs to build the document with recommendations.
4. Focus on Reasoning & Decision Support by evaluating generated frameworks.

#### Facilitation Notes
> üí° **Tips:**
> - Monitor for Word formatting issues during paste.
> - Checkpoint: Verify recommendations address USAF risks like maintenance downtime.
> - Troubleshooting: If analysis is shallow, add "provide comparative options."
> - Explain iteration benefits: Builds from basic to robust decisions.

#### Expected Outcomes
- ‚úÖ Created structured training plan in Word with recommendations.
- ‚úÖ Verified conflict analysis and decision frameworks.
- ‚úÖ Confirmed Reasoning & Decision Support via optimized suggestions.
- ‚úÖ Demonstrated prompt iterations for progressive refinement.

#### Discussion Points

**Meta-Prompting**
- How enhances: Refines prompts for A3 planning.
- Example: `"Help me create a prompt to draft a training plan. What details on risks and resources should I include?"`
- When valuable: For complex operations with multiple variables.

**Chain of Reasoning**
- How to apply: Guides logical breakdown.
- Example: `"Let's work through this step by step: 1) List training objectives. 2) Analyze conflicts. 3) Recommend solutions. 4) Prioritize based on readiness."`
- When improves quality: For mission briefs requiring justification.

**When to Use**
- Use for A3 reports to enhance decision quality.
- Trade-offs: Simple for outlines; complex for in-depth analysis.
- Real-world: Coordinating range time or mission rehearsals.

---

### Scenario 3: Data Analysis & Visualization
**Application:** Excel | **USAF Focus:** A4 (Logistics) | **Duration:** 20-25 min

#### Scenario Context
At Wright-Patterson AFB, an Airman First Class (E-3) in the Logistics Readiness Squadron is analyzing aircraft mission capable (MC) rates. This includes identifying maintenance patterns and suggesting visualizations for bottlenecks. The scenario illustrates Copilot's role in logistics insights.

#### Copilot Capability Focus
- Primary: Data Analysis & Visualization
- Sub-capabilities: Pattern identification, insight generation, chart recommendations
- Application to USAF: Aids A4 tasks like supply chain reports and MICAP tracking, per AFMAN 23-122.

#### Progressive Prompt Building

##### Iteration 1: Basic Prompt
```
Analyze this aircraft MC rate data.
```
- What this prompt does: Gives simple summary.
- Output example: Basic stats on rates.
- Limitations: No patterns or visuals mentioned.

##### Iteration 2: Add Context
```
Analyze this aircraft MC rate data for the 88th Air Base Wing at Wright-Patterson AFB, including patterns in maintenance issues.
```
- How context improves output: Adds USAF logistics focus.
- Comparison to iteration 1: Identifies specific trends like parts delays.

##### Iteration 3: Add Specificity
```
Analyze this aircraft MC rate data for the 88th Air Base Wing. Identify patterns in maintenance issues, generate insights on logistics bottlenecks, and recommend Excel visualizations like charts for leadership briefs.
```
- Why specificity matters: Targets actionable outputs.
- Improved output quality: Includes visual suggestions.

##### Iteration 4: Final Optimized Prompt
```
Analyze this aircraft MC rate data for the 88th Air Base Wing. Step by step: Identify patterns in maintenance, generate insights on supply chain impacts, recommend visualizations such as pivot charts, and suggest formulas for trend analysis per AFMAN 23-122.
```
- Final refinements: Adds formulas and standards.
- Complete output example: Insights + chart descriptions.

#### Technical Steps
1. Open Excel with sample MC rate data; copy data into Copilot Chat.
2. Paste Iteration 1 and generate analysis; copy insights back to Excel notes.
3. Refine to Iterations 2-4, pasting recommendations to create charts.
4. Emphasize Data Analysis & Visualization by applying suggested visuals.

#### Facilitation Notes
> üí° **Tips:**
> - Ensure data is pasted accurately without formulas breaking.
> - Checkpoint: Confirm patterns relate to USAF terms like "MICAP."
> - Troubleshooting: If visuals are vague, specify "Excel-compatible charts."
> - Explain iterations: Shows evolution from summary to visual insights.

#### Expected Outcomes
- ‚úÖ Analyzed data with patterns and insights in Excel.
- ‚úÖ Created recommended visualizations.
- ‚úÖ Confirmed Data Analysis & Visualization capability.
- ‚úÖ Showed iterative prompts for deeper analysis.

#### Discussion Points

**Meta-Prompting**
- How enhances: Builds prompts for A4 data tasks.
- Example: `"Help me create a prompt to analyze MC rates. What details on patterns and visuals should I include?"`
- When valuable: For datasets with hidden trends.

**Chain of Reasoning**
- How to apply: Structures analysis.
- Example: `"Let's work through this step by step: 1) Calculate averages. 2) Identify outliers. 3) Suggest causes. 4) Recommend charts."`
- When improves quality: For readiness reports needing evidence.

**When to Use**
- Use for logistics tracking to spot issues early.
- Trade-offs: Simple for quick stats; complex for briefs.
- Real-world: Supply requisitions or equipment audits.

---

### Scenario 4: Automation & Orchestration
**Application:** Power Automate | **USAF Focus:** A6 (Communications) | **Duration:** 20-25 min

#### Scenario Context
At Joint Base San Antonio, a Technical Sergeant (E-6) in the Communications Squadron is designing a workflow for AFNet help desk tickets. This includes routing requests, notifications, and resolution tracking. The scenario highlights Copilot in automating comms processes.

#### Copilot Capability Focus
- Primary: Automation & Orchestration
- Sub-capabilities: Workflow design, logic optimization, decision points
- Application to USAF: Streamlines A6 tasks like NIPR/SIPR access and IT support, compliant with AFI 17-100.

#### Progressive Prompt Building

##### Iteration 1: Basic Prompt
```
Design a workflow for help desk tickets.
```
- What this prompt does: Outlines simple steps.
- Output example: Basic flow diagram.
- Limitations: No USAF specifics or logic.

##### Iteration 2: Add Context
```
Design a workflow for AFNet help desk tickets at Joint Base San Antonio, including routing to techs and notifications.
```
- How context improves output: Incorporates comms environment.
- Comparison to iteration 1: Adds notifications for DoD users.

##### Iteration 3: Add Specificity
```
Design a workflow for AFNet help desk tickets at Joint Base San Antonio. Include automation logic for routing based on issue type, decision points for approvals, and tracking resolution times per AFI 17-100.
```
- Why specificity matters: Ensures functional logic.
- Improved output quality: Detailed steps with branches.

##### Iteration 4: Final Optimized Prompt
```
Design a workflow for AFNet help desk tickets at Joint Base San Antonio. Step by step: Define triggers, add routing logic for NIPR/SIPR issues, include notifications and approvals, optimize for efficiency, and troubleshoot potential errors.
```
- Final refinements: Adds troubleshooting.
- Complete output example: Full flow description with conditions.

#### Technical Steps
1. Open Power Automate; describe basic flow and copy to Copilot Chat.
2. Use Iteration 1 to generate design; paste back to build flow.
3. Iterate to 2-4, copying logic to add actions and conditions.
4. Focus on Automation & Orchestration by testing generated workflows.

#### Facilitation Notes
> üí° **Tips:**
> - Watch for Power Automate connector issues in DoD setup.
> - Checkpoint: Ensure logic handles USAF terms like "SIPR access."
> - Troubleshooting: If flow is incomplete, add "include error handling."
> - Explain iterations: Progresses from outline to optimized automation.

#### Expected Outcomes
- ‚úÖ Designed workflow with routing and tracking in Power Automate.
- ‚úÖ Verified logic and decision points.
- ‚úÖ Confirmed Automation & Orchestration capability.
- ‚úÖ Demonstrated prompt iterations for refinement.

#### Discussion Points

**Meta-Prompting**
- How enhances: Assists in workflow prompt design.
- Example: `"Help me create a prompt to design a help desk workflow. What logic and steps should I include?"`
- When valuable: For custom A6 automations.

**Chain of Reasoning**
- How to apply: Breaks down flow creation.
- Example: `"Let's work through this step by step: 1) Identify triggers. 2) Define conditions. 3) Add actions. 4) Test outcomes."`
- When improves quality: For complex IT processes.

**When to Use**
- Use for repetitive A6 tasks like ticket routing.
- Trade-offs: Simple for basic flows; complex for branched logic.
- Real-world: Access requests or network monitoring.

---

### Scenario 5: Search & Retrieval
**Application:** Power BI | **USAF Focus:** A2 (Intelligence) | **Duration:** 20-25 min

#### Scenario Context
At Nellis AFB, a 1st Lieutenant (O-2) in the Intelligence Flight is extracting threat indicators from dashboards for a wing brief. This involves finding data points and organizing summaries. The scenario shows Copilot aiding intelligence retrieval.

#### Copilot Capability Focus
- Primary: Search & Retrieval
- Sub-capabilities: Information extraction, data organization, consolidation
- Application to USAF: Supports A2 tasks like threat assessments and IPOE, per AFI 14-202.

#### Progressive Prompt Building

##### Iteration 1: Basic Prompt
```
Find threat indicators in this intelligence dashboard data.
```
- What this prompt does: Lists basic items.
- Output example: Unstructured list.
- Limitations: No organization or context.

##### Iteration 2: Add Context
```
Find specific threat indicators from this intelligence dashboard for Nellis AFB operations, including regional assessments.
```
- How context improves output: Ties to USAF intelligence.
- Comparison to iteration 1: Groups by threat type.

##### Iteration 3: Add Specificity
```
Extract key threat indicators from this intelligence dashboard for Nellis AFB. Organize into a structured brief with categories like cyber and kinetic threats, and consolidate for wing leadership per AFI 14-202.
```
- Why specificity matters: Ensures formatted output.
- Improved output quality: Structured sections.

##### Iteration 4: Final Optimized Prompt
```
Extract threat indicators from this intelligence dashboard for Nellis AFB. Step by step: Search for critical data points, organize by threat category, create a consolidated summary, and highlight priorities for ISR reports.
```
- Final refinements: Adds prioritization.
- Complete output example: Organized brief with bullets.

#### Technical Steps
1. Open Power BI with sample dashboard; copy data excerpts to Copilot Chat.
2. Paste Iteration 1 to extract; copy back to Power BI report.
3. Refine to Iterations 2-4, pasting organized outputs to build summaries.
4. Emphasize Search & Retrieval by verifying extracted accuracy.

#### Facilitation Notes
> üí° **Tips:**
> - Ensure data snippets are copied without visuals.
> - Checkpoint: Confirm outputs use A2 terms like "IPOE."
> - Troubleshooting: If extraction misses items, add "include all categories."
> - Explain iterations: Evolves from list to structured brief.

#### Expected Outcomes
- ‚úÖ Extracted and organized data in Power BI.
- ‚úÖ Created consolidated intelligence summary.
- ‚úÖ Confirmed Search & Retrieval capability.
- ‚úÖ Showed iterative prompts for better organization.

#### Discussion Points

**Meta-Prompting**
- How enhances: Refines extraction prompts.
- Example: `"Help me create a prompt to extract threat data. What categories and formats should I include?"`
- When valuable: For large intelligence datasets.

**Chain of Reasoning**
- How to apply: Guides systematic search.
- Example: `"Let's work through this step by step: 1) Identify key metrics. 2) Extract values. 3) Categorize threats. 4) Summarize impacts."`
- When improves quality: For detailed assessments.

**When to Use**
- Use for A2 reports to quickly retrieve info.
- Trade-offs: Simple for single queries; complex for briefs.
- Real-world: ISR summaries or threat updates.

---

### Scenario 6: Personalization & Context Awareness
**Application:** Teams | **USAF Focus:** A1 (Manpower & Personnel) | **Duration:** 20-25 min

#### Scenario Context
At Wright-Patterson AFB, a Captain (O-3) in the Personnel Flight is summarizing a promotion board meeting and generating follow-ups. This adapts to ranks and chain of command for tasks like assignments. The scenario demonstrates Copilot's contextual adaptation.

#### Copilot Capability Focus
- Primary: Personalization & Context Awareness
- Sub-capabilities: Terminology adaptation, role-specific suggestions, contextual summaries
- Application to USAF: Enhances A1 communications like promotion boards, using AFI 36-2501.

#### Progressive Prompt Building

##### Iteration 1: Basic Prompt
```
Summarize this meeting about promotion boards.
```
- What this prompt does: General overview.
- Output example: Neutral summary.
- Limitations: No USAF ranks or context.

##### Iteration 2: Add Context
```
Summarize this promotion board planning meeting for the 88th Air Base Wing, using USAF terminology like EPR/OPR.
```
- How context improves output: Incorporates military terms.
- Comparison to iteration 1: Adds relevance to A1 processes.

##### Iteration 3: Add Specificity
```
Summarize this promotion board planning meeting for the 88th Air Base Wing. Adapt to USAF context with rank structure, generate follow-up messages for sections, and ensure chain of command compliance per AFI 36-2501.
```
- Why specificity matters: Tailors to personas.
- Improved output quality: Rank-appropriate language.

##### Iteration 4: Final Optimized Prompt
```
Summarize this promotion board planning meeting for the 88th Air Base Wing. Adapt to context: Use USAF terminology, create agendas and follow-ups with rank-appropriate tone (e.g., for E-5 NCOs vs O-4 Officers), and demonstrate chain of command in communications.
```
- Final refinements: Emphasizes personalization.
- Complete output example: Summary + tailored messages.

#### Technical Steps
1. Open Teams and copy meeting notes to Copilot Chat.
2. Use Iteration 1 for basic summary; paste to Teams channel.
3. Iterate to 2-4, copying adapted outputs for agendas and messages.
4. Focus on Personalization & Context Awareness by checking rank adaptations.

#### Facilitation Notes
> üí° **Tips:**
> - Handle Teams formatting during paste.
> - Checkpoint: Verify messages respect chain of command.
> - Troubleshooting: If tone is off, specify "rank-appropriate."
> - Explain iterations: Shows personalization growth.

#### Expected Outcomes
- ‚úÖ Summarized notes with contextual adaptations in Teams.
- ‚úÖ Generated rank-appropriate follow-ups.
- ‚úÖ Confirmed Personalization & Context Awareness.
- ‚úÖ Demonstrated prompt iterations for context.

#### Discussion Points

**Meta-Prompting**
- How enhances: Builds contextual prompts.
- Example: `"Help me create a prompt to summarize meetings. What USAF details like ranks should I include?"`
- When valuable: For personnel communications.

**Chain of Reasoning**
- How to apply: Structures adaptations.
- Example: `"Let's work through this step by step: 1) Identify participants' ranks. 2) Summarize key points. 3) Adapt tone. 4) Generate follow-ups."`
- When improves quality: For hierarchical discussions.

**When to Use**
- Use for A1 meetings to ensure proper etiquette.
- Trade-offs: Simple for quick notes; complex for formal chains.
- Real-world: Assignment actions or leave coordination.

---

## Quick Reference

### Summary Table of All 6 Scenarios

| Scenario | Capability | Application | USAF Focus | Duration |
|----------|------------|-------------|------------|----------|
| 1 | Language Understanding & Generation | Outlook | A1 (Manpower & Personnel) | 20-25 min |
| 2 | Reasoning & Decision Support | Word | A3 (Operations) | 20-25 min |
| 3 | Data Analysis & Visualization | Excel | A4 (Logistics) | 20-25 min |
| 4 | Automation & Orchestration | Power Automate | A6 (Communications) | 20-25 min |
| 5 | Search & Retrieval | Power BI | A2 (Intelligence) | 20-25 min |
| 6 | Personalization & Context Awareness | Teams | A1 (Manpower & Personnel) | 20-25 min |

### Progressive Prompt Building Tips
- Start basic: Focus on core task.
- Add context: Include USAF details (ranks, AFIs).
- Specify: Define format, tone, structure.
- Optimize: Use step-by-step for depth.
- üîÑ Iterate 3-4 times to show improvements.

### Key Talking Points for Each Copilot Capability
- Language Understanding & Generation: Summarize and draft with tone.
- Reasoning & Decision Support: Analyze and recommend frameworks.
- Data Analysis & Visualization: Identify patterns and suggest charts.
- Automation & Orchestration: Design logic and optimize flows.
- Search & Retrieval: Extract and organize data.
- Personalization & Context Awareness: Adapt to context and roles.

### Meta-Prompting and Chain of Reasoning Quick Reference
- **Meta-Prompting:** Use to build better prompts. Example: `"Help me craft a prompt for [task]."`
- **Chain of Reasoning:** Explicit steps for logic. Example: `"Step by step: 1) [action] 2) [action]."`
- When to use: Meta for planning; Chain for analysis.

### Common Questions with Answers
- Q: Why no web grounding? A: DoD compliance restricts internet access.
- Q: How to handle errors? A: Refine prompts with more details.
- Q: Can scenarios connect? A: No, they are independent.

### Troubleshooting Common Issues
- Copy/paste fails: Use plain text mode.
- Outputs too generic: Add USAF context.
- App restrictions: Verify DoD permissions.
- ‚ö†Ô∏è Warning: Always use standalone Copilot Chat.

### Additional Learning Resources
- [Microsoft Learn: Copilot Fundamentals](https://learn.microsoft.com/en-us/microsoft-copilot/)
- [Microsoft Learn: Prompt Engineering](https://learn.microsoft.com/en-us/training/modules/engineer-copilot-prompts/)